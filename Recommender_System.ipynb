{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1213f4",
   "metadata": {},
   "source": [
    "# Part 2 Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597221de",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452bbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm as progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c19d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional recommender systems packages\n",
    "import surprise\n",
    "from surprise import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c720857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neural nets\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95295785",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium') # trade precision for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f84c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59b8d9",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198b0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y_test):\n",
    "    # should both be in numpy.array\n",
    "    return np.mean((y_pred - y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9da96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1424502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a04cb",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf7e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data in favor of surprise format\n",
    "filepath = os.path.join('data', 'rec.tsv')\n",
    "reader = surprise.Reader(line_format='user item rating', sep='\\t')\n",
    "data = surprise.Dataset.load_from_file(filepath, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9089bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = model_selection.train_test_split(data, test_size=.25)\n",
    "# must acknowledge the data leakage problem with time\n",
    "# it might be more wise to use leave-one-out testset based on lastest time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94013457",
   "metadata": {},
   "source": [
    "Notice that our dataset's majority is user / item which only relevant to very few amount of reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea86424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3543476368547949"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length = []\n",
    "for user in trainset.ur:\n",
    "    user_length.append(len(trainset.ur[user]))\n",
    "np.average(user_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b977b509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.155460029797524"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_length = []\n",
    "for item in trainset.ir:\n",
    "    item_length.append(len(trainset.ir[item]))\n",
    "np.average(item_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3977b8",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d7c24",
   "metadata": {},
   "source": [
    "Given a user-item pairs, predict possible ratings.\n",
    "\n",
    "**Evaluation**: Mean Squared Error & Round Accuracy on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb959f",
   "metadata": {},
   "source": [
    "### Baseline Model: Similarity-Based Rating Estimation\n",
    "\n",
    "Given a user, item pair: We consider all the items consumed by the user, we use its weighted (based on similarities) average of the user's ratings on all other items it used to predict its ratings on a new item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd146324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare item average dictionary\n",
    "item_average = {}\n",
    "for item in trainset.ir:\n",
    "    all_reviews = trainset.ir[item]\n",
    "    item_average[item] = np.mean([review[1] for review in all_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f925046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(user, item):\n",
    "    \n",
    "    try:\n",
    "        # from out id to inner id\n",
    "        user_iid = trainset.to_inner_uid(user)\n",
    "        item_iid = trainset.to_inner_iid(item)\n",
    "    except:\n",
    "        # if the user or item does not appear in the training dataset\n",
    "        return trainset.global_mean\n",
    "    \n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    \n",
    "    for review in trainset.ur[user_iid]:\n",
    "        another_item = review[0]\n",
    "        if another_item == item_iid:\n",
    "            continue # escape itself\n",
    "            \n",
    "        # get the ratings off average on the item's behavior\n",
    "        ratings.append(review[1] - item_average[another_item])\n",
    "        \n",
    "        users_this_item = set([review[0] for review in trainset.ir[item_iid]])\n",
    "        users_another_item = set([review[0] for review in trainset.ir[another_item]])\n",
    "        \n",
    "        similarities.append(Jaccard(users_this_item, users_another_item))\n",
    "    \n",
    "    if(sum(similarities) > 0):\n",
    "        weighted_ratings = [(x*y) for x, y in zip(ratings, similarities)]\n",
    "        return item_average[item_iid] + sum(weighted_ratings) / sum(similarities)\n",
    "    else:\n",
    "        return trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b84c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 772756/772756 [02:48<00:00, 4596.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# perform the prediction\n",
    "y_pred = []\n",
    "y_test = []\n",
    "for user, item, rating in progress_bar(testset):\n",
    "    y_pred.append(predict_ratings(user, item))\n",
    "    y_test.append(rating)\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942abf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9474959814844819"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set MSE\n",
    "MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e410f3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21011289462650565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set Accuracy\n",
    "accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89b552",
   "metadata": {},
   "source": [
    "### Latent Factor Model\n",
    "Based on the idea of k factors that represent different categories of user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "085a9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = surprise.SVD(n_factors=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29241d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.5 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit and predict\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966cc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prediction in predictions:\n",
    "    y_pred.append(prediction.est)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8fe292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6888076658234337"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set MSE\n",
    "MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c87e14cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2831695904011098"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set Accuracy\n",
    "accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ec683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del data, trainset, testset, item_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2c187",
   "metadata": {},
   "source": [
    "### Neural Network: *Neural Collaborative Filtering (NCF)*\n",
    "Reference: https://arxiv.org/abs/1708.05031\n",
    "\n",
    "Idea: Directly provide the network with encoded item and user, and let itself to analyze the recommendation.\n",
    "\n",
    "#### Reconstrcut the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "974ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('data', 'rec.tsv')\n",
    "data = pd.read_csv(filepath, sep='\\t', header=None).rename(columns = {0: 'user_id', 1: 'item_id', 2: 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8330b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the unique complex index into sequence of numbers\n",
    "data['user_id'], user_id_mapper = pd.factorize(data['user_id'])\n",
    "data['item_id'], item_id_mapper = pd.factorize(data['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "560d5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# split into train-test set\n",
    "trainset = data.iloc[:round(len(data) * 0.95)]\n",
    "testset = data.iloc[round(len(data) * 0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f91989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for training\n",
    "    \n",
    "    Input:\n",
    "        data (pd.DataFrame): DataFrame containing the product ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.users, self.items, self.ratings = self.get_dataset(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "    \n",
    "    def get_dataset(self, data):\n",
    "        return torch.tensor(data['user_id']), torch.tensor(data['item_id']), torch.tensor(data['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefc1da",
   "metadata": {},
   "source": [
    "#### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c73669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Nerual Collaborative Filtering\n",
    "    \n",
    "    Input:\n",
    "        num_users (int): number of unique users\n",
    "        num_items (int): number of unique items\n",
    "        data (pd.DataFrame): DataFrame contaniing the product ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, data):\n",
    "        super().__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=num_users, embedding_dim = 128)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_items, embedding_dim = 128)\n",
    "        self.fc1 = torch.nn.Linear(in_features=256, out_features=512)\n",
    "        self.fc2 = torch.nn.Linear(in_features=512, out_features=64)\n",
    "        self.output = torch.nn.Linear(in_features=64, out_features=1)\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        # pass through embedding layers\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "        \n",
    "        # Concat the two embedding layers\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "        \n",
    "        # fully connected layers\n",
    "        vector = torch.nn.ReLU()(self.fc1(vector))\n",
    "        vector = torch.nn.ReLU()(self.fc2(vector))\n",
    "        \n",
    "        # output layer \n",
    "        pred = self.output(vector)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = torch.nn.MSELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(Train_dataset(self.data), batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6399ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = data['user_id'].max() + 1\n",
    "num_items = data['item_id'].max() + 1\n",
    "\n",
    "model = NCF(num_users, num_items, trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe556c7c",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee22a9b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory C:\\Users\\keyuu\\OneDrive - UC San Diego\\Undergraduate\\4Junior Year\\WI\\Personal Projects\\Amazon_Reviews\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 275 M \n",
      "1 | item_embedding | Embedding | 23.8 M\n",
      "2 | fc1            | Linear    | 131 K \n",
      "3 | fc2            | Linear    | 32.8 K\n",
      "4 | output         | Linear    | 65    \n",
      "---------------------------------------------\n",
      "299 M     Trainable params\n",
      "0         Non-trainable params\n",
      "299 M     Total params\n",
      "1,197.994 Total estimated model params size (MB)\n",
      "c:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6148aaa15141a8b43a89bf8e688d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 35min 35s\n",
      "Wall time: 1h 35min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pl.Trainer(max_epochs=5, logger=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e375c6",
   "metadata": {},
   "source": [
    "#### Evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58a95b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = torch.tensor(testset['user_id'].to_numpy())\n",
    "test_item = torch.tensor(testset['item_id'].to_numpy())\n",
    "y_pred = model.forward(test_user, test_item).detach().numpy().flatten()\n",
    "y_test = testset['rating'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdf414f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7011991391584224"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set MSE\n",
    "MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f584fa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5145615363213437"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set Accuracy\n",
    "accuracy(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
